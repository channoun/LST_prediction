{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# prompt: mount\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3kZSbj_ug4s",
        "outputId": "1808e0c5-f4dc-4e41-c1a6-dfb7fcc78f61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A6sG2UT6nCR8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "277d5a70-7e1a-48ab-b14d-65fd2174ab87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on cuda\n"
          ]
        }
      ],
      "source": [
        "# Cell 1 ▶ Consolidated imports\n",
        "import os, math, glob, time\n",
        "import numpy as np, pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "import torch, torch.nn as nn, torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from tqdm import tqdm\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Running on\", device)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── Cell 1: Imports & Dataset ─────────────────────────────────────────────\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class DateTileDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Each row in file_to_meteo.csv gives:\n",
        "      - date: \"YYYY-MM-DD\"\n",
        "      - file_path: full path to X_YYYY-MM-DD.npy  (shape (N,6,6,8))\n",
        "      - air_temp_C, dew_point_C, relative_humidity_percent, wind_speed_m_s, precipitation_in\n",
        "    We load X (tiles×6×6×8), Y (tiles×K) from Y_imf_{date}.npy, and the 5-vector of weather.\n",
        "    \"\"\"\n",
        "    def __init__(self, lookup_csv, x_dir, y_dir):\n",
        "        self.meta  = pd.read_csv(lookup_csv)\n",
        "        self.x_dir = x_dir\n",
        "        self.y_dir = y_dir\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.meta)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row  = self.meta.iloc[idx]\n",
        "        date = row['date']\n",
        "        # load X, Y\n",
        "        X    = np.load(row['file_path'])                                    # (N,6,6,8)\n",
        "        Y    = np.load(os.path.join(self.y_dir, f\"Y_imf_{date}.npy\"))       # (N,K)\n",
        "\n",
        "        # weather vector\n",
        "        met  = row[['air_temp_C','dew_point_C',\n",
        "                    'relative_humidity_percent',\n",
        "                    'wind_speed_m_s','precipitation_in']].values.astype(np.float32)\n",
        "\n",
        "        # to torch\n",
        "        X    = torch.from_numpy(X).permute(0,3,1,2).float()  # (N,8,6,6)\n",
        "        Y    = torch.from_numpy(Y).float()                   # (N,K)\n",
        "        met  = torch.from_numpy(met).float()                 # (5,)\n",
        "\n",
        "        return X, met, Y"
      ],
      "metadata": {
        "id": "tc5GIfIonF1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── Cell 2: train/val split & DataLoaders ─────────────────────────────────\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# adjust these to your Drive paths:\n",
        "LOOKUP_CSV = \"/content/drive/MyDrive/EarthEngine/file_to_meteo.csv\"\n",
        "X_DIR      = \"/content/drive/MyDrive/EarthEngine/X\"\n",
        "Y_DIR      = \"/content/drive/MyDrive/EarthEngine/Y_imf\"\n",
        "\n",
        "# load & split by date\n",
        "lookup = pd.read_csv(LOOKUP_CSV)\n",
        "val_df = lookup.sample(frac=0.2, random_state=42).reset_index(drop=True)\n",
        "tr_df  = lookup.drop(val_df.index).reset_index(drop=True)\n",
        "\n",
        "# Cell 2 ▶ wrap in Dataset, then override .meta\n",
        "train_ds = DateTileDataset(\n",
        "    x_dir       = X_DIR,\n",
        "    y_dir       = Y_DIR,\n",
        "    lookup_csv  = LOOKUP_CSV   # <— point at your CSV!\n",
        ")\n",
        "train_ds.meta = tr_df           # now replace with just the train rows\n",
        "\n",
        "val_ds = DateTileDataset(\n",
        "    x_dir       = X_DIR,\n",
        "    y_dir       = Y_DIR,\n",
        "    lookup_csv  = LOOKUP_CSV\n",
        ")\n",
        "val_ds.meta = val_df            # replace with just the val rows\n",
        "\n",
        "# DataLoaders not used directly (we iterate per-date inside our loop)\n",
        "# but you could also flatten every tile into one giant loader:\n",
        "# train_loader = DataLoader(train_ds, batch_size=1, shuffle=True)\n"
      ],
      "metadata": {
        "id": "qPzYXx9JT32A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3 ▶ Model, optimizer, AMP, etc.\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "\n",
        "# ── 1) Define your network class ─────────────────────────────────────────\n",
        "class PIHPNet_SingleScale(nn.Module):\n",
        "    def __init__(self, in_gscfm=5, in_idx=3, meteo_in=5, hidden=64, K=3):\n",
        "        super().__init__()\n",
        "        self.enc_g = nn.Sequential(\n",
        "            nn.Conv2d(in_gscfm, 32, 3, padding=1), nn.ReLU(),\n",
        "            nn.Conv2d(32,   64, 3, padding=1), nn.ReLU(),\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "        )\n",
        "        self.enc_i = nn.Sequential(\n",
        "            nn.Conv2d(in_idx, 32, 3, padding=1), nn.ReLU(),\n",
        "            nn.Conv2d(32,    64, 3, padding=1), nn.ReLU(),\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "        )\n",
        "        self.metmlp = nn.Sequential(\n",
        "            nn.Linear(meteo_in, hidden), nn.ReLU(),\n",
        "            nn.Linear(hidden,    hidden), nn.ReLU(),\n",
        "        )\n",
        "        fuse_dim = 64 + 64 + hidden\n",
        "        self.heads = nn.ModuleList([\n",
        "            nn.Sequential(\n",
        "                nn.Linear(fuse_dim, fuse_dim//2), nn.ReLU(),\n",
        "                nn.Linear(fuse_dim//2, 1),\n",
        "            ) for _ in range(K)\n",
        "        ])\n",
        "\n",
        "    def forward(self, X, met):\n",
        "        gscfm = X[:,:5]\n",
        "        idx   = X[:,5:]\n",
        "        fg    = self.enc_g(gscfm).view(X.size(0), -1)\n",
        "        fi    = self.enc_i(idx).view(X.size(0), -1)\n",
        "        fm    = self.metmlp(met).expand(X.size(0), -1)\n",
        "        H     = torch.cat([fg, fi, fm], dim=1)\n",
        "        out   = [head(H) for head in self.heads]\n",
        "        return torch.cat(out, dim=1)\n",
        "\n",
        "# ── 2) Instantiate & move to GPU ─────────────────────────────────────────\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model   = PIHPNet_SingleScale().to(device)\n",
        "\n",
        "# ── 3) Loss, optimizer, scaler ────────────────────────────────────────────\n",
        "crit    = nn.MSELoss()\n",
        "opt     = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
        "scaler  = GradScaler() if torch.cuda.is_available() else None\n",
        "clip_val = 5.0\n",
        "mini_bs  = 512\n",
        "epochs   = 10\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKtb9dSPsdCi",
        "outputId": "678bdcc8-62f6-4992-ecfa-391d177a1d1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-06b8d261dea5>:50: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler  = GradScaler() if torch.cuda.is_available() else None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── Cell 4: Training + Validation Loop ────────────────────────────────────\n",
        "from tqdm import tqdm\n",
        "\n",
        "for ep in range(1, epochs+1):\n",
        "    # — TRAIN —\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    seen_tiles   = 0\n",
        "\n",
        "    print(f\"\\n=== Epoch {ep}/{epochs} TRAIN ===\")\n",
        "    for _, row in tr_df.sample(frac=1).iterrows():\n",
        "        date   = row['date']\n",
        "        X_all  = np.load(row['file_path'])\n",
        "        Y_all  = np.load(f\"{Y_DIR}/Y_imf_{date}.npy\")\n",
        "        N      = X_all.shape[0]\n",
        "\n",
        "        met = torch.tensor([\n",
        "            row.air_temp_C, row.dew_point_C,\n",
        "            row.relative_humidity_percent,\n",
        "            row.wind_speed_m_s, row.precipitation_in\n",
        "        ], device=device, dtype=torch.float32)\n",
        "\n",
        "        perm = np.random.permutation(N)\n",
        "        pbar = tqdm(total=N, desc=date, unit='tiles', leave=False)\n",
        "        for i in range(0, N, mini_bs):\n",
        "            idx = perm[i:i+mini_bs]\n",
        "            Xb  = torch.from_numpy(X_all[idx]).permute(0,3,1,2).to(device)\n",
        "            Yb  = torch.from_numpy(Y_all[idx]).to(device)\n",
        "            mb  = met.unsqueeze(0).expand(len(idx), -1)\n",
        "\n",
        "            opt.zero_grad()\n",
        "            with autocast(enabled=scaler is not None):\n",
        "                pred = model(Xb, mb)\n",
        "                loss = crit(pred, Yb)\n",
        "            if scaler:\n",
        "                scaler.scale(loss).backward()\n",
        "                gnorm = nn.utils.clip_grad_norm_(model.parameters(), clip_val)\n",
        "                scaler.step(opt)\n",
        "                scaler.update()\n",
        "            else:\n",
        "                loss.backward()\n",
        "                gnorm = nn.utils.clip_grad_norm_(model.parameters(), clip_val)\n",
        "                opt.step()\n",
        "\n",
        "            b = len(idx)\n",
        "            running_loss += loss.item() * b\n",
        "            seen_tiles   += b\n",
        "            pbar.set_postfix(loss=f\"{running_loss/seen_tiles:.4f}\", gnorm=f\"{min(gnorm,clip_val):.1f}\")\n",
        "            pbar.update(b)\n",
        "        pbar.close()\n",
        "\n",
        "    print(f\"→ TRAIN MSE/tile: {running_loss/seen_tiles:.6f}\")\n",
        "\n",
        "    # — VALIDATE —\n",
        "    model.eval()\n",
        "    val_loss  = 0.0\n",
        "    val_tiles = 0\n",
        "\n",
        "    print(f\"=== Epoch {ep}/{epochs}  VAL ===\")\n",
        "    for _, row in val_df.iterrows():\n",
        "        date   = row['date']\n",
        "        X_all  = np.load(row['file_path'])\n",
        "        Y_all  = np.load(f\"{Y_DIR}/Y_imf_{date}.npy\")\n",
        "        N      = X_all.shape[0]\n",
        "\n",
        "        met = torch.tensor([\n",
        "            row.air_temp_C, row.dew_point_C,\n",
        "            row.relative_humidity_percent,\n",
        "            row.wind_speed_m_s, row.precipitation_in\n",
        "        ], device=device, dtype=torch.float32)\n",
        "\n",
        "        pbar = tqdm(total=N, desc=date, unit='tiles', leave=False)\n",
        "        with torch.no_grad():\n",
        "            for i in range(0, N, mini_bs):\n",
        "                idx = range(i, min(i+mini_bs, N))\n",
        "                Xb  = torch.from_numpy(X_all[idx]).permute(0,3,1,2).to(device)\n",
        "                Yb  = torch.from_numpy(Y_all[idx]).to(device)\n",
        "                mb  = met.unsqueeze(0).expand(len(idx), -1)\n",
        "\n",
        "                pred = model(Xb, mb)\n",
        "                loss = crit(pred, Yb)\n",
        "\n",
        "                b = len(idx)\n",
        "                val_loss  += loss.item() * b\n",
        "                val_tiles += b\n",
        "                pbar.set_postfix(loss=f\"{val_loss/val_tiles:.4f}\")\n",
        "                pbar.update(b)\n",
        "        pbar.close()\n",
        "\n",
        "    print(f\"→  VAL MSE/tile: {val_loss/val_tiles:.6f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiS13IqZAfVF",
        "outputId": "ec68447c-9b45-49a4-ce05-50a96a343f26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Epoch 1/10 TRAIN ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r2020-01-17:   0%|          | 0/1658958 [00:00<?, ?tiles/s]<ipython-input-12-155e0420ae60>:32: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=scaler is not None):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "→ TRAIN MSE/tile: 164.707179\n",
            "=== Epoch 1/10  VAL ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "→  VAL MSE/tile: 241.935916\n",
            "\n",
            "=== Epoch 2/10 TRAIN ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "→ TRAIN MSE/tile: 179.397527\n",
            "=== Epoch 2/10  VAL ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "→  VAL MSE/tile: 226.650128\n",
            "\n",
            "=== Epoch 3/10 TRAIN ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "→ TRAIN MSE/tile: 171.356009\n",
            "=== Epoch 3/10  VAL ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "→  VAL MSE/tile: 218.715704\n",
            "\n",
            "=== Epoch 4/10 TRAIN ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "→ TRAIN MSE/tile: 193.143114\n",
            "=== Epoch 4/10  VAL ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "→  VAL MSE/tile: 216.074303\n",
            "\n",
            "=== Epoch 5/10 TRAIN ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "cannot reshape array of size 167903200 into shape (1659888,6,6,8)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-155e0420ae60>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtr_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mdate\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mX_all\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'file_path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mY_all\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{Y_DIR}/Y_imf_{date}.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mN\u001b[0m      \u001b[0;34m=\u001b[0m \u001b[0mX_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/lib/_npyio_impl.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    482\u001b[0m                                           max_header_size=max_header_size)\n\u001b[1;32m    483\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m                 return format.read_array(fid, allow_pickle=allow_pickle,\n\u001b[0m\u001b[1;32m    485\u001b[0m                                          \u001b[0mpickle_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m                                          max_header_size=max_header_size)\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs, max_header_size)\u001b[0m\n\u001b[1;32m    864\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 866\u001b[0;31m             \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 167903200 into shape (1659888,6,6,8)"
          ]
        }
      ]
    }
  ]
}